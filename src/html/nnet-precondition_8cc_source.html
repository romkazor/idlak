<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Kaldi: nnet2/nnet-precondition.cc Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="favicon.ico" type="image/x-icon" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" /> 
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
 <td id="projectlogo"><a href="http://kaldi-asr.org/"><img alt="Logo" src="KaldiTextAndLogoSmall.png"/ style="padding: 3px 5px 1px 5px"></a></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname" style="display:none">Kaldi
   </div>
  </td>
    <td style="padding-left: 0.5em;">
    <div id="projectbrief" style="display:none"></div>
    </td>
   <!--END PROJECT_BRIEF-->
  <!--END !PROJECT_NAME-->
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('nnet-precondition_8cc_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">nnet-precondition.cc</div>  </div>
</div><!--header-->
<div class="contents">
<a href="nnet-precondition_8cc.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// nnet2/nnet-precondition.cc</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Copyright 2012   Johns Hopkins University (author: Daniel Povey)</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// See ../../COPYING for clarification regarding multiple authors</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment">// you may not use this file except in compliance with the License.</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">// You may obtain a copy of the License at</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">//  http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment">// THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">// WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">// MERCHANTABLITY OR NON-INFRINGEMENT.</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">// See the Apache 2 License for the specific language governing permissions and</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">// limitations under the License.</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="nnet-precondition_8h.html">nnet2/nnet-precondition.h</a>&quot;</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacekaldi.html">kaldi</a> {</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="keyword">namespace </span>nnet2 {</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno"><a class="line" href="namespacekaldi_1_1nnet2.html#af25337b8d10c63cb5a7dfb06cb732f17">   26</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="namespacekaldi_1_1nnet2.html#af25337b8d10c63cb5a7dfb06cb732f17">PreconditionDirections</a>(<span class="keyword">const</span> <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> &amp;R,</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;                            <span class="keywordtype">double</span> lambda,</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;                            <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> *P) {</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;  </div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;  int32 N = R.<a class="code" href="classkaldi_1_1CuMatrixBase.html#a01cf7fccddf8deddc75b34408144ded1">NumRows</a>(), D = R.<a class="code" href="classkaldi_1_1CuMatrixBase.html#acd4c9f53536602585f5aff9e8005299a">NumCols</a>();</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(<a class="code" href="group__matrix__funcs__io.html#ga07b147212efb08775c252cd4cc7453fe">SameDim</a>(R, *P) &amp;&amp; N &gt; 0);</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;  <span class="keywordflow">if</span> (N == 1) {</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;Trying to precondition set of only one frames: returning &quot;</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;               &lt;&lt; <span class="stringliteral">&quot;unchanged.  Ignore this warning if infrequent.&quot;</span>;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;    P-&gt;<a class="code" href="classkaldi_1_1CuMatrixBase.html#a79817f1cbd9d8478d4137d6dd815a584">CopyFromMat</a>(R);</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;    <span class="keywordflow">return</span>;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;  }</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;  <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> &amp;Q = *P;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;  </div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  <span class="keywordflow">if</span> (N &gt;= D) {</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    <span class="comment">// Compute G = (\lambda I + 1/(N-1) R^T R)^{-1} by direct inversion.</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    <span class="comment">// G &lt;-- lambda I.</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    <a class="code" href="classkaldi_1_1CuMatrix.html">CuMatrix&lt;BaseFloat&gt;</a> G(D, D);</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    G.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ae8e87b09ccd8a23d31dbc415a60da637">AddToDiag</a>(lambda);</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;    <span class="comment">// G += 1.0/(N-1) * R^T R.</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;    G.<a class="code" href="classkaldi_1_1CuMatrixBase.html#a9b29a25c5f85d5a970594c2fcbb3c044">SymAddMat2</a>(1.0 / (N-1), R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kTrans</a>, 1.0);</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;    G.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ae71f2e6355f884d16edf9539e24adbb5">CopyLowerToUpper</a>();</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="group__error__group.html#gae77f5cf98f18f8cbe207690e49da166e">GetVerboseLevel</a>() &gt;= 5 &amp;&amp; <a class="code" href="namespacekaldi.html#a70777edd81d4056098f79b9cd3bffb8b">Rand</a>() % 20 == 0) {</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;      <a class="code" href="classkaldi_1_1CuSpMatrix.html">CuSpMatrix&lt;BaseFloat&gt;</a> tmp(G, <a class="code" href="namespacekaldi.html#a1e7deac168cc2b1002cc25ab544d0f90ab23bc41c203345e3a080b4f011f7aa40">kTakeLower</a>);</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;      <a class="code" href="classkaldi_1_1SpMatrix.html">SpMatrix&lt;BaseFloat&gt;</a> G_cpu(tmp);</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;      G_cpu.<a class="code" href="classkaldi_1_1SpMatrix.html#a64b8caf99fcad4132d32c92b58880ff8">PrintEigs</a>(<span class="stringliteral">&quot;G&quot;</span>);</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    }</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    G.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ab7590e6a76e5d8757d361703ff47bbb0">SymInvertPosDef</a>();</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    <span class="comment">// Q &lt;-- R G^T (we just make it transposed as we think</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    <span class="comment">// it will be slightly faster; it&#39;s symmetric).</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    Q.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ac6680e67841f62c6cf1b52d13b58546d">AddMatMat</a>(1.0, R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d">kNoTrans</a>, G, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kTrans</a>, 0.0);</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    <span class="comment">// Through a lot of rearrangements, it turns out that</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <span class="comment">// if we let  S = (\lambda I + 1/(N-1) R R^T)^{-1}</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    <span class="comment">// then what we need is</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;    <span class="comment">// Q &lt;-- S R.</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    <span class="comment">// It is curious and (to me) unexpected that the actual code is basically</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    <span class="comment">// the same when transposed.</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;    <a class="code" href="classkaldi_1_1CuMatrix.html">CuMatrix&lt;BaseFloat&gt;</a> S(N, N);</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;    <span class="comment">// S &lt;-- lambda I.</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    S.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ae8e87b09ccd8a23d31dbc415a60da637">AddToDiag</a>(lambda);</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <span class="comment">// S += (N-1) R R^T.</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    <span class="comment">// the following function only updates the lower triangle.</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    S.<a class="code" href="classkaldi_1_1CuMatrixBase.html#a9b29a25c5f85d5a970594c2fcbb3c044">SymAddMat2</a>(1.0 / (N-1), R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d">kNoTrans</a>, 1.0);</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    S.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ae71f2e6355f884d16edf9539e24adbb5">CopyLowerToUpper</a>();</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="comment">// invert S, so now S = (\lambda I + (N-1) R R^T)^{-1}.</span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="group__error__group.html#gae77f5cf98f18f8cbe207690e49da166e">GetVerboseLevel</a>() &gt;= 5 &amp;&amp; <a class="code" href="namespacekaldi.html#a70777edd81d4056098f79b9cd3bffb8b">Rand</a>() % 20 == 0) {</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;      <a class="code" href="classkaldi_1_1CuSpMatrix.html">CuSpMatrix&lt;BaseFloat&gt;</a> tmp(S, <a class="code" href="namespacekaldi.html#a1e7deac168cc2b1002cc25ab544d0f90ab23bc41c203345e3a080b4f011f7aa40">kTakeLower</a>);</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;      <a class="code" href="classkaldi_1_1SpMatrix.html">SpMatrix&lt;BaseFloat&gt;</a> S_cpu(tmp);</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;      S_cpu.<a class="code" href="classkaldi_1_1SpMatrix.html#a64b8caf99fcad4132d32c92b58880ff8">PrintEigs</a>(<span class="stringliteral">&quot;S&quot;</span>);</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    }</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    S.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ab7590e6a76e5d8757d361703ff47bbb0">SymInvertPosDef</a>();</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    Q.<a class="code" href="classkaldi_1_1CuMatrixBase.html#ac6680e67841f62c6cf1b52d13b58546d">AddMatMat</a>(1.0, S, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d">kNoTrans</a>, R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d">kNoTrans</a>, 0.0);</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;  }</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="preprocessor">#if 0  // Old code before it was optimized for CUDA:</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;  <span class="keywordflow">for</span> (int32 <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a> = 0; <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a> &lt; N; <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>++) {</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;    <a class="code" href="classkaldi_1_1CuSubVector.html">CuSubVector&lt;BaseFloat&gt;</a> r(R, <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>), q(Q, <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    <a class="code" href="namespacekaldi.html#aa66ff8367094543664b3b6a13d77c139">BaseFloat</a> gamma = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(r, q), <span class="comment">// gamma_n = r_n^T q_n.</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;               beta = 1 + gamma / (N - 1 - gamma);</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keywordflow">if</span> (!(gamma &gt;= 0.0 &amp;&amp; beta &gt; 0.0)) {</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;      <a class="code" href="group__error__group.html#ga0251fa005e2fdb1dcc6e24f06afe3b1f">KALDI_ERR</a> &lt;&lt; <span class="stringliteral">&quot;Bad values encountered in preconditioning: gamma = &quot;</span> &lt;&lt; gamma</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;                &lt;&lt; <span class="stringliteral">&quot;, beta = &quot;</span> &lt;&lt; beta;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="comment">// Q and P share the same memory.  The result of the</span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    <span class="comment">// scaling below will be output as P.</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    q.<a class="code" href="classkaldi_1_1CuVectorBase.html#ac54802d75d4c9025310b579e3fcea00c">Scale</a>(beta);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;  }</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;  <a class="code" href="classkaldi_1_1CuVector.html">CuVector&lt;BaseFloat&gt;</a> gamma(N);</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  gamma.<a class="code" href="classkaldi_1_1CuVectorBase.html#a46c4e5094335a6e257a08cb9ae0e7ff0">AddDiagMatMat</a>(1.0, R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d">kNoTrans</a>, Q, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kTrans</a>, 0.0);</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;  <span class="comment">// at this point, gamma(i) equals the i&#39;th row of R dotted with</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  <span class="comment">// the i&#39;th row of Q.</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;  <a class="code" href="classkaldi_1_1Vector.html">Vector&lt;BaseFloat&gt;</a> cpu_gamma(gamma), cpu_beta(N, <a class="code" href="namespacekaldi.html#ab4ace1fea44c7724ab9a76d70abad80baf2cd3231820315500697550960956126">kUndefined</a>);</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;  <span class="keywordflow">for</span> (int32 <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a> = 0; <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a> &lt; N; <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>++) {</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    <a class="code" href="namespacekaldi.html#aa66ff8367094543664b3b6a13d77c139">BaseFloat</a> this_gamma = cpu_gamma(<a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>),</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        this_beta = 1.0 + this_gamma / (N - 1 - this_gamma);</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    <span class="keywordflow">if</span> (!(this_gamma &gt;= 0.0 &amp;&amp; this_beta &gt; 0.0))</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;      <a class="code" href="group__error__group.html#ga0251fa005e2fdb1dcc6e24f06afe3b1f">KALDI_ERR</a> &lt;&lt; <span class="stringliteral">&quot;Bad values encountered in preconditioning: gamma = &quot;</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;                &lt;&lt; this_gamma &lt;&lt; <span class="stringliteral">&quot;, beta = &quot;</span> &lt;&lt; this_beta;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    cpu_beta(<a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>) = this_beta;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;  }</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;  <a class="code" href="classkaldi_1_1CuVector.html">CuVector&lt;BaseFloat&gt;</a> beta(cpu_beta);</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;  P-&gt;<a class="code" href="classkaldi_1_1CuMatrixBase.html#a9316d4a8c6a73dfadbf9e8417e70a514">MulRowsVec</a>(beta);</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;}</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="namespacekaldi_1_1nnet2.html#a4a199b32ed158301df174b4b4a52edb2">  114</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="namespacekaldi_1_1nnet2.html#a4a199b32ed158301df174b4b4a52edb2">PreconditionDirectionsAlpha</a>(</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;    <span class="keyword">const</span> <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> &amp;R,</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="keywordtype">double</span> alpha,</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> *P) {</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(alpha &gt; 0.0);</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;  <span class="comment">// probably does not really make sense.</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;  <span class="keywordtype">double</span> t = <a class="code" href="namespacekaldi.html#a94b9f349754706b9d6f38bb5ccc11c77">TraceMatMat</a>(R, R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kTrans</a>), floor = 1.0e-20;</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;  <span class="keywordflow">if</span> (t &lt; floor) {</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;Flooring trace from &quot;</span> &lt;&lt; t</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;               &lt;&lt; <span class="stringliteral">&quot; to &quot;</span> &lt;&lt; floor;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;    t = floor;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;  }</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;  <span class="keywordtype">double</span> lambda = t * alpha / R.<a class="code" href="classkaldi_1_1CuMatrixBase.html#a01cf7fccddf8deddc75b34408144ded1">NumRows</a>() / R.<a class="code" href="classkaldi_1_1CuMatrixBase.html#acd4c9f53536602585f5aff9e8005299a">NumCols</a>();</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;  <span class="comment">// see the extended comment below for an explanation of this.</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;  <span class="keywordflow">if</span> (lambda &lt;= 0.0) {</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;    <span class="comment">// This should never really happen, it would probably indicate a bug</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    <span class="comment">// in the calling code.</span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;Zero or negative lambda in PreconditionDirectionsAlpha.&quot;</span>;</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;    lambda = 1.0e-10;</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;  }</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;  <a class="code" href="namespacekaldi_1_1nnet2.html#af25337b8d10c63cb5a7dfb06cb732f17">PreconditionDirections</a>(R, lambda, P);</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;}</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno"><a class="line" href="namespacekaldi_1_1nnet2.html#a8d1d9b8171ab8e9a3c26bf3160f774fc">  138</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="namespacekaldi_1_1nnet2.html#a8d1d9b8171ab8e9a3c26bf3160f774fc">PreconditionDirectionsAlphaRescaled</a>(</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    <span class="keyword">const</span> <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> &amp;R,</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    <span class="keywordtype">double</span> alpha,</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    <a class="code" href="classkaldi_1_1CuMatrixBase.html">CuMatrixBase&lt;BaseFloat&gt;</a> *P) {</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(alpha &gt; 0.0); <span class="comment">// alpha &gt; 1.0</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;  <span class="comment">// probably does not really make sense.</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;  <span class="keywordtype">double</span> t = <a class="code" href="namespacekaldi.html#a94b9f349754706b9d6f38bb5ccc11c77">TraceMatMat</a>(R, R, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kTrans</a>), floor = 1.0e-20;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;  <span class="keywordflow">if</span> (t == 0.0) {</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    P-&gt;<a class="code" href="classkaldi_1_1CuMatrixBase.html#a79817f1cbd9d8478d4137d6dd815a584">CopyFromMat</a>(R);</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    <span class="keywordflow">return</span>;</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;  }</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;  <span class="keywordflow">if</span> (t &lt; floor) {</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;Flooring trace from &quot;</span> &lt;&lt; t</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;               &lt;&lt; <span class="stringliteral">&quot; to &quot;</span> &lt;&lt; floor;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    t = floor;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;  }</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;  <span class="keywordtype">double</span> lambda = t * alpha / R.<a class="code" href="classkaldi_1_1CuMatrixBase.html#a01cf7fccddf8deddc75b34408144ded1">NumRows</a>() / R.<a class="code" href="classkaldi_1_1CuMatrixBase.html#acd4c9f53536602585f5aff9e8005299a">NumCols</a>();</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;  <span class="comment">// see the extended comment below for an explanation of this.</span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(lambda != 0.0);</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;  <a class="code" href="namespacekaldi_1_1nnet2.html#af25337b8d10c63cb5a7dfb06cb732f17">PreconditionDirections</a>(R, lambda, P);</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;  <span class="keywordtype">double</span> p_trace = <a class="code" href="namespacekaldi.html#a94b9f349754706b9d6f38bb5ccc11c77">TraceMatMat</a>(*P, *P, <a class="code" href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kTrans</a>),</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;      rescale = sqrt(t / p_trace);</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(p_trace != 0.0);</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;  P-&gt;<a class="code" href="classkaldi_1_1CuMatrixBase.html#ac54802d75d4c9025310b579e3fcea00c">Scale</a>(rescale);</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;}</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;} <span class="comment">// namespace nnet2</span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;} <span class="comment">// namespace kaldi</span></div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment">  Notes for an idea on preconditioning.</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment">  update is of form:</span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="comment">     params += learning_rate * input_row * output_deriv&#39;</span></div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="comment">  want to precondition by fisher-like matrix in each of (the input dim and the</span></div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment">  output dim).</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment">  [note: in this method we&#39;ll pretend the chunk-weights are all one.</span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment">   It shouldn&#39;t really matter, it&#39;s only preconditioning.]</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment">   The first observation is, if we do:</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment">    params += learning_rate * S * input_row * output_deriv&#39; * T</span></div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">   for any positive definite S and T that we choose (well, perhaps we have</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="comment">   to ensure their eigenvalues are bounded in some way, but we&#39;ll bother with</span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment">   that later),  then we&#39;ll still get convergence.  But S and T cannot be</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">   functions of the current sample, the one that creates &quot;input_row&quot; and</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">   &quot;output_deriv&quot;, or this introduces a bias.</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment">   We can view it as a preconditioning of the vectorized form of the</span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="comment">   transformation matrix.</span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;<span class="comment">   For a Fisher-like preconditioning, we can precondition using</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="comment">   the inverse of the scatter of the other features in the batch.</span></div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;<span class="comment">   For the input_row, call this r_j.</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="comment">   Let the total scatter be</span></div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;<span class="comment">    S =  \sum_n r_n r_n^T</span></div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;<span class="comment">  where the sum is taken over the minibatch, and</span></div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;<span class="comment">   S_n = S - r_n  r_n^T</span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="comment">  i.e. the scatter with this sample removed.</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="comment">  Let F_n be the normalized version of this, dividing by the #samples.</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="comment">   F_n = 1/(N-1) S_n</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="comment">  where N is the minibatch size (so N-1 is excluding the current sample).</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="comment"> We&#39;re going to want to invert F_n, so we need to make it positive definite.</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment">  We&#39;re going to define G_n as a smoothed form of the estimated Fisher matrix</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="comment">  for this batch:</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="comment">   G_n = F_n + \lambda_n I</span></div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="comment">  where I is the identity.  A suitable formula for \lambda_n is to define</span></div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;<span class="comment">  a small constant \alpha (say, \alpha=0.1), and let</span></div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;<span class="comment">  </span></div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;<span class="comment">   \lambda_n =  (\alpha/dim(F)) trace(F_n) .</span></div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;<span class="comment">  In practice (although we lost strict convergence guarantees) it will be easier</span></div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="comment">  to set a global \lambda, to:</span></div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="comment">   \lambda  =  (\alpha/dim(S)) trace(S)</span></div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment">            = (\alpha/(R.NumRows()*R.NumCols()) * trace(R^T R)).</span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="comment">  </span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="comment">  This is an easy way to set it.  Let&#39;s define P_n as the inverse of G_n.  This</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment">  is what we&#39;ll be multiplying the input values by:</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment">    P_n = G_n^{-1} = (F_n + \lambda_n I)^{-1}</span></div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="comment">  First, let&#39;s define an uncorrected &quot;global&quot; Fisher matrix</span></div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="comment">    F = (1/(N-1)) S_n,</span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;<span class="comment">  and G = F^{-1}.</span></div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="comment">  If we let R be the matrix each of whose rows is one of the r_n,</span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="comment">  then</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="comment">    S = R^T R, and</span></div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="comment">   F = 1/(N-1) R^T R</span></div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment">           G = (F + \lambda I)^{-1}</span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment">             = (1/(N-1) R^T R + \lambda I)^{-1}</span></div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment">Using the Woodbury formula,</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment">     G  = (1/\lambda) I  - (1/\lambda^2) R^T M R</span></div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment">where</span></div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment">  M = ((N-1) I + 1/\lambda R R^T)^{-1}</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment">(and this inversion for M is actually done as an inversion, in a lower</span></div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;<span class="comment"> dimension such as 250, versus the actual dimension which might be 1000).</span></div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;<span class="comment">Let&#39;s assume \lambda is a constant, i.e. there is no \lambda_n.</span></div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;<span class="comment">We can get it from the previous minibatch.</span></div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;<span class="comment"> We want to compute</span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;<span class="comment">    G_n = F_n^{-1} = (F - 1/(N-1) r_n r_n^T)^{-1}</span></div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;<span class="comment"> and using the Sherman-Morrison formula, this may be written as:</span></div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;<span class="comment">   G_n = G  +  \alpha_n q_n q_n^T  # Caution: \alpha_n has nothing to do with \alpha.</span></div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="comment"> where q_n = G r_n, and</span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="comment"> \alpha_n =  1/( (N-1) (1 - 1/(N-1) r_n^T q_n) )</span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;<span class="comment">          =  1 / (N - 1 - r_n^T q_n)</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="comment">  We&#39;ll want to compute this efficiently.  For each r_n we&#39;ll want to compute</span></div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;<span class="comment"> p_n =  G_n r_n</span></div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment"> which will correspond to the direction we update in.</span></div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="comment"> We&#39;ll use</span></div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;<span class="comment">  p_n = G r_n + \alpha_n q_n q_n^T r_n</span></div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="comment">  and since q_n = G r_n, both terms in this equation point in</span></div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;<span class="comment">  the same direction, and we can write this as:</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;<span class="comment">  p_n = \beta_n q_n,</span></div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;<span class="comment">  where, defining \gamma_n = r_n^T q_n, we have</span></div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;<span class="comment">  \beta_n = 1 + \gamma_n \alpha_n </span></div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;<span class="comment">          = 1  +  \gamma_n / ((N-1) (1 - \gamma_n/(N-1)))</span></div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="comment">          = 1  +  \gamma_n / (N - 1 - \gamma_n)</span></div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;<span class="comment">  </span></div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;<span class="comment">*/</span></div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;<span class="comment">  SUMMARY:</span></div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;<span class="comment">   let the input features (we can extend these with a 1 for the bias term) be</span></div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;<span class="comment">   a matrix R, each row of which corresponds to a training example r_n</span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;<span class="comment">   The dimension of R is N x D, where N is the minibatch size and D is the</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="comment">   dimension of the input to this layer of the network.</span></div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;<span class="comment">   We&#39;ll be computing a matrix P, each row p_n of which will be the corresponding</span></div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="comment">   row r_n of R, multiplied by a positive definite preconditioning matrix G_n.</span></div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;<span class="comment">   [we can check that for each i, p_n^T r_n &gt;= 0].</span></div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;<span class="comment">   The following computation obtains P:</span></div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;<span class="comment">   \lambda &lt;-- (\alpha/N) \trace(R R^T).   # 0 &lt; \alpha &lt;= 1 is a global constant, e.g.</span></div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="comment">                                           # \alpha = 0.1, but should try different</span></div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;<span class="comment">                                           # values, this will be important (note: if the</span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;<span class="comment">                                           # minibatch size is &gt;= the dimension (N &gt;= D),</span></div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment">                                           # then we can let \alpha be quite small, e.g.</span></div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;<span class="comment">                                           # 0.001.</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="comment">   if N &gt;= D, then</span></div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment">     # compute G by direct inversion.</span></div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="comment">     G &lt;-- (\lambda I  +  1/(N-1) R^T R)^{-1}</span></div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="comment">     Q &lt;-- R G.</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;<span class="comment">   else   # number of samples is less than dimension, use</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;<span class="comment">          # morrison-Woodbury formula, it&#39;s more efficient.</span></div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="comment">      # We&#39;d first compute:</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="comment">      # L &lt;-- ((N-1) I + 1/\lambda R R^T)</span></div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;<span class="comment">      # (note: L is something that appears in the morrison-Woodbury expansion of G)</span></div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;<span class="comment">      # M &lt;-- L^{-1}</span></div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">      # Note: G is  1/\lambda I  -  (1/\lambda^2) R^T M R</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="comment">      # We&#39;re doing Q &lt;-- R G, which is:</span></div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment">      # Q &lt;-- 1/\lambda R - (1/\lambda^2) R (R^T M R)</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment">      # It&#39;s more efficient in this case to left-multiply R</span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;<span class="comment">      # by something, i.e. bracket as:</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment">      # Q &lt;-- 1/\lambda R - (1/\lambda^2) (R R^T M) R</span></div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="comment">      # so let&#39;s write it as</span></div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="comment">      # Q &lt;-- S R, with</span></div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="comment">      # S = 1/\lambda I - 1/\lambda^2 R R^T M</span></div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;<span class="comment">      #   = 1/\lambda (I - 1/\lambda R R^T M)</span></div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;<span class="comment">      # Now, -1/\lambda R R^T = (N-1) I - L, and L M = I, so</span></div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment">      # S = 1/\lambda (I  + ((N-1) I - L) M)</span></div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="comment">      #   = (N-1)/\lambda M</span></div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;<span class="comment">      # and we can get rid of that scalar earlier on:</span></div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="comment">      # if we let L&#39; = \lambda/(N-1) L, so that</span></div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;<span class="comment">      # L&#39; = (lambda I + 1/(N-1) R R^T)</span></div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;<span class="comment">      # then</span></div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;<span class="comment">      # S = (\lambda I + 1/(N-1) R R^T)^{-1}. </span></div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;<span class="comment">      S &lt;-- (\lambda I + 1/(N-1) R R^T)^{-1}.</span></div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;<span class="comment">      Q &lt;-- S R</span></div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="comment">   fi</span></div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="comment">   Here, we&#39;re right multiplying each row r_n of r by the symmetric matrix G, to get</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;<span class="comment">   the corresponding row q_n of q.  Note: in practice Q will be the same memory as P.</span></div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="comment">   Next we work out for each n:</span></div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;<span class="comment">     \gamma_n = r_n^T q_n     # This should be nonnegative!  Check this.</span></div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="comment">      \beta_n = 1  +  \gamma_n / (N - 1 - \gamma_n)  # This should be positive; check this.</span></div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;<span class="comment">  For each n, we&#39;ll do (for the corresponding rows of P and Q):</span></div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;<span class="comment">     p_n &lt;-- \beta_n q_n.</span></div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment">  In practice, we&#39;d do this computation in-place, with P and Q using the</span></div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="comment">  same memory.</span></div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;<span class="comment">  If we&#39;re being paranoid, we should verify that</span></div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;<span class="comment">   p_n = (\lambda I  +  1/(N-1) \sum_{m != n} r_n r_n^T)^{-1} r_n.</span></div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;<span class="comment">  This is exact mathematically, but there could be differences due to roundoff,</span></div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;<span class="comment">  and if \alpha is quite small, these differences could be substantial.</span></div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;<span class="comment">  </span></div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;    </div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;</div><div class="ttc" id="classkaldi_1_1CuMatrixBase_html_a79817f1cbd9d8478d4137d6dd815a584"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#a79817f1cbd9d8478d4137d6dd815a584">kaldi::CuMatrixBase::CopyFromMat</a></div><div class="ttdeci">void CopyFromMat(const MatrixBase&lt; OtherReal &gt; &amp;src, MatrixTransposeType trans=kNoTrans)</div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l00339">cu-matrix.cc:339</a></div></div>
<div class="ttc" id="namespacekaldi_html"><div class="ttname"><a href="namespacekaldi.html">kaldi</a></div><div class="ttdoc">Relabels neural network egs with the read pdf-id alignments. </div><div class="ttdef"><b>Definition:</b> <a href="chain_8dox_source.html#l00020">chain.dox:20</a></div></div>
<div class="ttc" id="classkaldi_1_1SpMatrix_html"><div class="ttname"><a href="classkaldi_1_1SpMatrix.html">kaldi::SpMatrix</a></div><div class="ttdoc">Packed symetric matrix class. </div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00062">matrix-common.h:62</a></div></div>
<div class="ttc" id="namespacekaldi_html_ab4ace1fea44c7724ab9a76d70abad80baf2cd3231820315500697550960956126"><div class="ttname"><a href="namespacekaldi.html#ab4ace1fea44c7724ab9a76d70abad80baf2cd3231820315500697550960956126">kaldi::kUndefined</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00039">matrix-common.h:39</a></div></div>
<div class="ttc" id="classkaldi_1_1CuVector_html"><div class="ttname"><a href="classkaldi_1_1CuVector.html">kaldi::CuVector</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00074">matrix-common.h:74</a></div></div>
<div class="ttc" id="group__error__group_html_gae77f5cf98f18f8cbe207690e49da166e"><div class="ttname"><a href="group__error__group.html#gae77f5cf98f18f8cbe207690e49da166e">kaldi::GetVerboseLevel</a></div><div class="ttdeci">int32 GetVerboseLevel()</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00057">kaldi-error.h:57</a></div></div>
<div class="ttc" id="namespacekaldi_1_1nnet2_html_a4a199b32ed158301df174b4b4a52edb2"><div class="ttname"><a href="namespacekaldi_1_1nnet2.html#a4a199b32ed158301df174b4b4a52edb2">kaldi::nnet2::PreconditionDirectionsAlpha</a></div><div class="ttdeci">void PreconditionDirectionsAlpha(const CuMatrixBase&lt; BaseFloat &gt; &amp;R, double alpha, CuMatrixBase&lt; BaseFloat &gt; *P)</div><div class="ttdoc">This wrapper for PreconditionDirections computes lambda using  = /(N D) trace(R^T, R), and calls PreconditionDirections. </div><div class="ttdef"><b>Definition:</b> <a href="nnet-precondition_8cc_source.html#l00114">nnet-precondition.cc:114</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_ae8e87b09ccd8a23d31dbc415a60da637"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#ae8e87b09ccd8a23d31dbc415a60da637">kaldi::CuMatrixBase::AddToDiag</a></div><div class="ttdeci">void AddToDiag(Real value)</div><div class="ttdoc">Adds &quot;value&quot; to the diagonal elements of the matrix. </div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l00570">cu-matrix.cc:570</a></div></div>
<div class="ttc" id="namespacekaldi_1_1nnet2_html_af25337b8d10c63cb5a7dfb06cb732f17"><div class="ttname"><a href="namespacekaldi_1_1nnet2.html#af25337b8d10c63cb5a7dfb06cb732f17">kaldi::nnet2::PreconditionDirections</a></div><div class="ttdeci">void PreconditionDirections(const CuMatrixBase&lt; BaseFloat &gt; &amp;R, double lambda, CuMatrixBase&lt; BaseFloat &gt; *P)</div><div class="ttdoc">See below for comment. </div><div class="ttdef"><b>Definition:</b> <a href="nnet-precondition_8cc_source.html#l00026">nnet-precondition.cc:26</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrix_html"><div class="ttname"><a href="classkaldi_1_1CuMatrix.html">kaldi::CuMatrix</a></div><div class="ttdoc">This class represents a matrix that&amp;#39;s stored on the GPU if we have one, and in memory if not...</div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00071">matrix-common.h:71</a></div></div>
<div class="ttc" id="classkaldi_1_1CuSpMatrix_html"><div class="ttname"><a href="classkaldi_1_1CuSpMatrix.html">kaldi::CuSpMatrix</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00076">matrix-common.h:76</a></div></div>
<div class="ttc" id="classkaldi_1_1CuSubVector_html"><div class="ttname"><a href="classkaldi_1_1CuSubVector.html">kaldi::CuSubVector</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00073">matrix-common.h:73</a></div></div>
<div class="ttc" id="classkaldi_1_1CuVectorBase_html_a46c4e5094335a6e257a08cb9ae0e7ff0"><div class="ttname"><a href="classkaldi_1_1CuVectorBase.html#a46c4e5094335a6e257a08cb9ae0e7ff0">kaldi::CuVectorBase::AddDiagMatMat</a></div><div class="ttdeci">void AddDiagMatMat(Real alpha, const CuMatrixBase&lt; Real &gt; &amp;M, MatrixTransposeType transM, const CuMatrixBase&lt; Real &gt; &amp;N, MatrixTransposeType transN, Real beta=1.0)</div><div class="ttdoc">Add the diagonal of a matrix product: *this = diag(M N), assuming the &quot;trans&quot; arguments are both kNoT...</div><div class="ttdef"><b>Definition:</b> <a href="cu-vector_8cc_source.html#l00583">cu-vector.cc:583</a></div></div>
<div class="ttc" id="namespacekaldi_html_a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2"><div class="ttname"><a href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa538d6ef272b2ad113f1860fccbc2c3e2">kaldi::kTrans</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00033">matrix-common.h:33</a></div></div>
<div class="ttc" id="classkaldi_1_1SpMatrix_html_a64b8caf99fcad4132d32c92b58880ff8"><div class="ttname"><a href="classkaldi_1_1SpMatrix.html#a64b8caf99fcad4132d32c92b58880ff8">kaldi::SpMatrix::PrintEigs</a></div><div class="ttdeci">void PrintEigs(const char *name)</div><div class="ttdef"><b>Definition:</b> <a href="sp-matrix_8h_source.html#l00203">sp-matrix.h:203</a></div></div>
<div class="ttc" id="group__matrix__funcs__io_html_ga07b147212efb08775c252cd4cc7453fe"><div class="ttname"><a href="group__matrix__funcs__io.html#ga07b147212efb08775c252cd4cc7453fe">kaldi::SameDim</a></div><div class="ttdeci">bool SameDim(const MatrixBase&lt; Real &gt; &amp;M, const MatrixBase&lt; Real &gt; &amp;N)</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-matrix_8h_source.html#l01065">kaldi-matrix.h:1065</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_ac54802d75d4c9025310b579e3fcea00c"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#ac54802d75d4c9025310b579e3fcea00c">kaldi::CuMatrixBase::Scale</a></div><div class="ttdeci">void Scale(Real value)</div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l00610">cu-matrix.cc:610</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_ab7590e6a76e5d8757d361703ff47bbb0"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#ab7590e6a76e5d8757d361703ff47bbb0">kaldi::CuMatrixBase::SymInvertPosDef</a></div><div class="ttdeci">void SymInvertPosDef()</div><div class="ttdoc">Inversion for positive definite symmetric matrices. </div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l02094">cu-matrix.cc:2094</a></div></div>
<div class="ttc" id="namespacekaldi_html_aa66ff8367094543664b3b6a13d77c139"><div class="ttname"><a href="namespacekaldi.html#aa66ff8367094543664b3b6a13d77c139">kaldi::BaseFloat</a></div><div class="ttdeci">float BaseFloat</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-types_8h_source.html#l00029">kaldi-types.h:29</a></div></div>
<div class="ttc" id="namespacernnlm_html_ab4871778d570f724a07823e0a2fb9884"><div class="ttname"><a href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">rnnlm::n</a></div><div class="ttdeci">struct rnnlm::@11::@12 n</div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_a9b29a25c5f85d5a970594c2fcbb3c044"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#a9b29a25c5f85d5a970594c2fcbb3c044">kaldi::CuMatrixBase::SymAddMat2</a></div><div class="ttdeci">void SymAddMat2(const Real alpha, const CuMatrixBase&lt; Real &gt; &amp;M, MatrixTransposeType transA, Real beta)</div><div class="ttdoc">*this = beta * *this + alpha * M M^T, for symmetric matrices. </div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l01340">cu-matrix.cc:1340</a></div></div>
<div class="ttc" id="group__error__group_html_ga0251fa005e2fdb1dcc6e24f06afe3b1f"><div class="ttname"><a href="group__error__group.html#ga0251fa005e2fdb1dcc6e24f06afe3b1f">KALDI_ERR</a></div><div class="ttdeci">#define KALDI_ERR</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00126">kaldi-error.h:126</a></div></div>
<div class="ttc" id="namespacekaldi_html_a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d"><div class="ttname"><a href="namespacekaldi.html#a610f4f6c3c8fe58b76713f593b9d724fa6decd3b781a809d748e5221d49f0ab5d">kaldi::kNoTrans</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00034">matrix-common.h:34</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_ac6680e67841f62c6cf1b52d13b58546d"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#ac6680e67841f62c6cf1b52d13b58546d">kaldi::CuMatrixBase::AddMatMat</a></div><div class="ttdeci">void AddMatMat(Real alpha, const CuMatrixBase&lt; Real &gt; &amp;A, MatrixTransposeType transA, const CuMatrixBase&lt; Real &gt; &amp;B, MatrixTransposeType transB, Real beta)</div><div class="ttdoc">C = alpha * A(^T)*B(^T) + beta * C. </div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l01278">cu-matrix.cc:1278</a></div></div>
<div class="ttc" id="group__error__group_html_ga994be213ddf127b5d6f20a43a02b513a"><div class="ttname"><a href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a></div><div class="ttdeci">#define KALDI_WARN</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00129">kaldi-error.h:129</a></div></div>
<div class="ttc" id="namespacekaldi_html_a94b9f349754706b9d6f38bb5ccc11c77"><div class="ttname"><a href="namespacekaldi.html#a94b9f349754706b9d6f38bb5ccc11c77">kaldi::TraceMatMat</a></div><div class="ttdeci">Real TraceMatMat(const MatrixBase&lt; Real &gt; &amp;A, const MatrixBase&lt; Real &gt; &amp;B, MatrixTransposeType trans)</div><div class="ttdoc">We need to declare this here as it will be a friend function. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-matrix_8cc_source.html#l02646">kaldi-matrix.cc:2646</a></div></div>
<div class="ttc" id="nnet-precondition_8h_html"><div class="ttname"><a href="nnet-precondition_8h.html">nnet-precondition.h</a></div></div>
<div class="ttc" id="namespacekaldi_html_a70777edd81d4056098f79b9cd3bffb8b"><div class="ttname"><a href="namespacekaldi.html#a70777edd81d4056098f79b9cd3bffb8b">kaldi::Rand</a></div><div class="ttdeci">int Rand(struct RandomState *state)</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-math_8cc_source.html#l00044">kaldi-math.cc:44</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_ae71f2e6355f884d16edf9539e24adbb5"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#ae71f2e6355f884d16edf9539e24adbb5">kaldi::CuMatrixBase::CopyLowerToUpper</a></div><div class="ttdeci">void CopyLowerToUpper()</div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l02936">cu-matrix.cc:2936</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html">kaldi::CuMatrixBase</a></div><div class="ttdoc">Matrix for CUDA computing. </div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00069">matrix-common.h:69</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_acd4c9f53536602585f5aff9e8005299a"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#acd4c9f53536602585f5aff9e8005299a">kaldi::CuMatrixBase::NumCols</a></div><div class="ttdeci">MatrixIndexT NumCols() const</div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8h_source.html#l00215">cu-matrix.h:215</a></div></div>
<div class="ttc" id="classkaldi_1_1Vector_html"><div class="ttname"><a href="classkaldi_1_1Vector.html">kaldi::Vector</a></div><div class="ttdoc">A class representing a vector. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8h_source.html#l00390">kaldi-vector.h:390</a></div></div>
<div class="ttc" id="group__error__group_html_gad5710173d69cddcda4fa21ded3c77f16"><div class="ttname"><a href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a></div><div class="ttdeci">#define KALDI_ASSERT(cond)</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00168">kaldi-error.h:168</a></div></div>
<div class="ttc" id="classkaldi_1_1CuVectorBase_html_ac54802d75d4c9025310b579e3fcea00c"><div class="ttname"><a href="classkaldi_1_1CuVectorBase.html#ac54802d75d4c9025310b579e3fcea00c">kaldi::CuVectorBase::Scale</a></div><div class="ttdeci">void Scale(Real value)</div><div class="ttdef"><b>Definition:</b> <a href="cu-vector_8cc_source.html#l01181">cu-vector.cc:1181</a></div></div>
<div class="ttc" id="namespacekaldi_html_a1e7deac168cc2b1002cc25ab544d0f90ab23bc41c203345e3a080b4f011f7aa40"><div class="ttname"><a href="namespacekaldi.html#a1e7deac168cc2b1002cc25ab544d0f90ab23bc41c203345e3a080b4f011f7aa40">kaldi::kTakeLower</a></div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00050">matrix-common.h:50</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_a01cf7fccddf8deddc75b34408144ded1"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#a01cf7fccddf8deddc75b34408144ded1">kaldi::CuMatrixBase::NumRows</a></div><div class="ttdeci">MatrixIndexT NumRows() const</div><div class="ttdoc">Dimensions. </div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8h_source.html#l00214">cu-matrix.h:214</a></div></div>
<div class="ttc" id="group__matrix__funcs__scalar_html_ga4750cd6f7a02a013435779588056b153"><div class="ttname"><a href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">kaldi::VecVec</a></div><div class="ttdeci">Real VecVec(const VectorBase&lt; Real &gt; &amp;a, const VectorBase&lt; Real &gt; &amp;b)</div><div class="ttdoc">Returns dot product between v1 and v2. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00037">kaldi-vector.cc:37</a></div></div>
<div class="ttc" id="classkaldi_1_1CuMatrixBase_html_a9316d4a8c6a73dfadbf9e8417e70a514"><div class="ttname"><a href="classkaldi_1_1CuMatrixBase.html#a9316d4a8c6a73dfadbf9e8417e70a514">kaldi::CuMatrixBase::MulRowsVec</a></div><div class="ttdeci">void MulRowsVec(const CuVectorBase&lt; Real &gt; &amp;scale)</div><div class="ttdoc">scale i&amp;#39;th row by scale[i] </div><div class="ttdef"><b>Definition:</b> <a href="cu-matrix_8cc_source.html#l00779">cu-matrix.cc:779</a></div></div>
<div class="ttc" id="namespacekaldi_1_1nnet2_html_a8d1d9b8171ab8e9a3c26bf3160f774fc"><div class="ttname"><a href="namespacekaldi_1_1nnet2.html#a8d1d9b8171ab8e9a3c26bf3160f774fc">kaldi::nnet2::PreconditionDirectionsAlphaRescaled</a></div><div class="ttdeci">void PreconditionDirectionsAlphaRescaled(const CuMatrixBase&lt; BaseFloat &gt; &amp;R, double alpha, CuMatrixBase&lt; BaseFloat &gt; *P)</div><div class="ttdoc">This wrapper for PreconditionDirections computes lambda using  = /(N D) trace(R^T, R), and calls PreconditionDirections. </div><div class="ttdef"><b>Definition:</b> <a href="nnet-precondition_8cc_source.html#l00138">nnet-precondition.cc:138</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_59421e7f380e574ca9527496739b16ca.html">nnet2</a></li><li class="navelem"><a class="el" href="nnet-precondition_8cc.html">nnet-precondition.cc</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
